{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "877b7f63-117f-4f49-99c7-8821c7c26fec",
   "metadata": {},
   "source": [
    "# Tag Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6203ff30-8a9e-4739-9b5a-674741f7aaa4",
   "metadata": {},
   "source": [
    "This tutorial aims to guide you through how we prepare raw tag data.\n",
    "\n",
    "**The main goal of this preparation is to ensure that the time stamps are expressed in UTC**.\n",
    "\n",
    "First, we will detail what we mean by ''raw data''.\n",
    "Then, we present what the processing consists in.\n",
    "Finally, we apply it to an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c2c926-6e89-4bee-afa7-bc296f36d695",
   "metadata": {},
   "source": [
    "## Raw Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c50661b-a823-439a-b5dc-70af270735ea",
   "metadata": {},
   "source": [
    "We expect the raw data of a given tag `id` to be located in a specific folder in the GFTS bucket.\n",
    "The latter should have 4 `.csv` files:\n",
    "- **For _`id`.csv_** contains the recorded data as a table entitled by _Date Time Stamp_, _Pressure_ and _Temp_.\n",
    "- **_acoustic.csv_** contains the acoustic detections of the fish (for instance, by stations). In case of no detection, the file is an empty table.\n",
    "\n",
    "  Otherwise, we expect the columns _date\\_time_, _deployment\\_id_, _deploy\\_longitude_ and _deploy\\_latitude_.\n",
    "- **_metadata.csv_** contains information about the tag. It can be any tabular data.\n",
    "- **_tagging_events\\_`id`.csv_** contains the times and positions of the release and recapture events.\n",
    "\n",
    "  We expect a 2 by 4 tabular file, entitled by _event*_, _time_, _longitude_ and _latitude_. The _event*_ column is the index, whose values describe the events, e.g., ''release'' and ''fish death''.\n",
    "  The recapture information can contain `nan` longitude and latitude values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d075de0c-9f68-43c1-b685-826c4e329c12",
   "metadata": {},
   "source": [
    "## Processing Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b0d6c0-6f92-4cae-8ec5-f5fd6009c315",
   "metadata": {},
   "source": [
    "In the following, we present the 4 functions to process each file mentioned above.\n",
    "Here a brief description of their objectives:\n",
    "- **For _`id`.csv_:** the time stamps are converted to UTC time and the columns are renamed to _temperature_ and _pressure_.\n",
    "- **For _acoustic.csv_:** the time stamps are converted to UTC time.\n",
    "- **For _metadata.csv_:** the file is loaded as a `DataFrame` and then exported as a `.json` file.\n",
    "- **For _tagging_events\\_`id`.csv_:** the time stamps are converted to UTC and the columns renamed to _event_name_, _longitude_ and _latitude_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa67de5-ec3b-46b9-8921-5cf5cef2acd4",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc0f269b-f9de-4aeb-a92a-6e534c8fdecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from s3fs.core import S3FileSystem\n",
    "import pandas as pd\n",
    "import io\n",
    "## counter-intuitive specifications! See:\n",
    "# https://en.wikipedia.org/wiki/Tz_database#Area\n",
    "# https://pvlib-python.readthedocs.io/en/stable/user_guide/timetimezones.html#fixed-offsets\n",
    "\n",
    "\n",
    "def process_dst(\n",
    "    file_path: str, s3: S3FileSystem, time_zone=\"Etc/GMT-2\", time_col_index=0\n",
    "):\n",
    "    \"\"\"\n",
    "    Process a `.csv` file containing the recorded time series of a tagged fish.\n",
    "\n",
    "    :param file_path: Path of the file.\n",
    "    :type file_path: str\n",
    "    :param s3: The file system of the S3 bucket.\n",
    "    :type S3FileSystem: str\n",
    "    :param time_zone: The time zone corresponding to the GMT offset within the time stamps, defaults to \"Etc/GMT-2\".\n",
    "    :type time_zone: str\n",
    "    :param time_col_index: Index of the time column, defaults to 0.\n",
    "    :type time_col_index: int\n",
    "    :return: The processed DataFrame.\n",
    "    :rtype: pd.DataFrame\n",
    "    \"\"\"\n",
    "    with s3.open(file_path, \"rb\") as f:\n",
    "        # assigns a new column \"time\" as the index\n",
    "        df = (\n",
    "            pd.read_csv(f)\n",
    "            .assign(\n",
    "                time=lambda df: pd.to_datetime(\n",
    "                    df.iloc[:, time_col_index], dayfirst=True\n",
    "                )\n",
    "            )\n",
    "            .set_index(\"time\")\n",
    "        )\n",
    "        # removes any assumption of the time zone with None and relocalizes to time_zone + UTC conversion\n",
    "        df = df.tz_localize(time_zone).tz_convert(\"UTC\").iloc[:, 1:3]\n",
    "        df.columns = [\"pressure\", \"temperature\"]\n",
    "    return df\n",
    "\n",
    "\n",
    "def process_tagging_event(file_path: str, s3: S3FileSystem, time_zone=\"Etc/GMT-2\"):\n",
    "    \"\"\"\n",
    "    Process a `.csv` file containing the tagging events (release and recapture) of a tagged fish.\n",
    "\n",
    "    :param file_path: Path of the file.\n",
    "    :type file_path: str\n",
    "    :param s3: The file system of the S3 bucket.\n",
    "    :type S3FileSystem: str\n",
    "    :param time_zone: The time zone corresponding to the GMT offset within the time stamps, defaults to \"Etc/GMT-2\".\n",
    "    :type time_zone: str\n",
    "    :return: The processed DataFrame.\n",
    "    :rtype: pd.DataFrame\n",
    "    \"\"\"\n",
    "    # TODO: Mathieu told me that times are already given as UTC+2? Ok so it is good\n",
    "    # TODO: input a more friendly time zone such as Europe/Paris and compute the GMT shift\n",
    "    with s3.open(file_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    cleaned_lines = []\n",
    "    for line in lines:\n",
    "        cleaned_line = line.strip().strip('\"').replace(\"\\t\", \"\")\n",
    "        cleaned_lines.append(cleaned_line)\n",
    "\n",
    "    # assigns a new column \"time\" as the index\n",
    "    df = (\n",
    "        pd.read_csv(io.StringIO(\"\\n\".join(cleaned_lines)))\n",
    "        .assign(time=lambda df: pd.to_datetime(df[\"time\"]))\n",
    "        .set_index(\"time\")\n",
    "    )\n",
    "    # removes any assumption of the time zone with None and relocalizes to time_zone + UTC conversion\n",
    "    df = df.tz_convert(None).tz_localize(time_zone).tz_convert(\"UTC\")\n",
    "    df.columns = [\"event_name\", \"longitude\", \"latitude\"]\n",
    "    return df\n",
    "\n",
    "\n",
    "def process_metadata(file_path: str, s3: S3FileSystem):\n",
    "    \"\"\"\n",
    "    Open a `.csv` file located in a S3 bucket with `pandas` as a `DataFrame`.\n",
    "\n",
    "    :param file_path: Path of the file.\n",
    "    :type file_path: str\n",
    "    :param s3: The file system of the S3 bucket.\n",
    "    :type S3FileSystem: str\n",
    "    :return: A DataFrame.\n",
    "    :rtype: pd.DataFrame\n",
    "    \"\"\"\n",
    "    with s3.open(file_path, \"rb\") as f:\n",
    "        df = pd.read_csv(f)\n",
    "    return df\n",
    "\n",
    "\n",
    "def process_acoustic_data(\n",
    "    file_path: str, s3: S3FileSystem, time_zone=\"UTC\", time_col_index=0\n",
    "):\n",
    "    \"\"\"\n",
    "    Process a `.csv` file containing a time series of ponctual detections of a tagged fish by acoustic receivers.\n",
    "\n",
    "    :param file_path: Path of the file.\n",
    "    :type file_path: str\n",
    "    :param s3: The file system of the S3 bucket.\n",
    "    :type S3FileSystem: str\n",
    "    :param time_zone: The time zone corresponding to the GMT offset within the time stamps, defaults to \"UTC\".\n",
    "    :type time_zone: str\n",
    "    :param time_col_index: Index of the time column, defaults to 0.\n",
    "    :type time_col_index: int\n",
    "    :return: The processed DataFrame.\n",
    "    :rtype: pd.DataFrame\n",
    "    \"\"\"\n",
    "    # TODO: check again with Mathieu that **the acoustic data is assumed to be given in UTC**.\n",
    "    with s3.open(file_path, \"rb\") as f:\n",
    "        # assigns a new column \"time\" as the index\n",
    "        df = (\n",
    "            pd.read_csv(f)\n",
    "            .assign(\n",
    "                time=lambda df: pd.to_datetime(\n",
    "                    df.iloc[:, time_col_index], dayfirst=True, format=\"ISO8601\"\n",
    "                )\n",
    "            )\n",
    "            .set_index(\"time\")\n",
    "        )\n",
    "        # removes any assumption of the time zone with None and relocalizes to time_zone + UTC conversion\n",
    "        df = df.tz_localize(time_zone).tz_convert(\"UTC\")\n",
    "        df.drop([\"date_time\"], axis=\"columns\", inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c870cdd-dc6d-4baa-b1f4-61e2fed56493",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "First, let's define variable to access the S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a181ecd-2a82-487c-ac64-e6c76aa65ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "import pandas as pd  # noqa: F811\n",
    "import io  # noqa: F811\n",
    "\n",
    "storage_options = {\n",
    "    \"anon\": False,\n",
    "    \"profile\": \"gfts\",\n",
    "    \"client_kwargs\": {\n",
    "        \"endpoint_url\": \"https://s3.gra.perf.cloud.ovh.net/\",\n",
    "        \"region_name\": \"gra\",\n",
    "    },\n",
    "}\n",
    "remote_dir = \"gfts-ifremer/tag_data_demo/\"\n",
    "s3 = s3fs.S3FileSystem(**storage_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e750ad97-62e0-4639-9a37-a0b6b9357e46",
   "metadata": {},
   "source": [
    "The raw files are located here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bffc39a-01c1-4e52-bcb2-8cec4c39e495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gfts-ifremer/tag_data_demo/A123456.csv',\n",
       " 'gfts-ifremer/tag_data_demo/acoustic.csv',\n",
       " 'gfts-ifremer/tag_data_demo/metadata.csv',\n",
       " 'gfts-ifremer/tag_data_demo/tagging_events_A123456.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3.ls(remote_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b95663a0-0ccb-4362-aa32-4dae291e0975",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "local_dir = \"tag_data_demo\"\n",
    "output_path = Path(local_dir)\n",
    "output_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "788e6a31-153a-46eb-8178-3808ceb231ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_zone = \"Etc/GMT-2\"\n",
    "date_format = \"%Y-%m-%dT%H:%M:%SZ\"\n",
    "device_id = \"A123456\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8cb466-6f59-4149-a3ea-4447ac7e863e",
   "metadata": {},
   "source": [
    "Then, let's process each file and store locally the results in the output directory (`tag_data_demo`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1008e72a-6482-49c1-a712-267cd09e6979",
   "metadata": {},
   "outputs": [],
   "source": [
    "acoustic_df = process_acoustic_data(remote_dir + \"acoustic.csv\", s3, time_zone=\"UTC\")\n",
    "acoustic_df.to_csv(output_path / \"acoustic.csv\", date_format=date_format)\n",
    "\n",
    "event_tags_df = process_tagging_event(\n",
    "    remote_dir + f\"tagging_events_{device_id}.csv\", s3, time_zone\n",
    ")\n",
    "event_tags_df.to_csv(output_path / \"tagging_events.csv\", date_format=date_format)\n",
    "\n",
    "\n",
    "dst_df = process_dst(remote_dir + f\"{device_id}.csv\", s3, time_zone)\n",
    "dst_df.to_csv(output_path / \"dst.csv\", date_format=date_format)\n",
    "\n",
    "\n",
    "md_df = process_metadata(remote_dir + \"metadata.csv\", s3)\n",
    "md_df.to_json(output_path / \"metadata.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952c59d7-87f1-478b-a73a-65754f8943f1",
   "metadata": {},
   "source": [
    "#### Biologging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1a659e0-5fed-4890-97b1-4be0d05ca26d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pressure</th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-05-21 22:00:00+00:00</th>\n",
       "      <td>1.751477</td>\n",
       "      <td>17.514350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-05-21 22:01:30+00:00</th>\n",
       "      <td>1.477457</td>\n",
       "      <td>17.898020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-05-21 22:03:00+00:00</th>\n",
       "      <td>1.741089</td>\n",
       "      <td>19.238910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-05-21 22:04:30+00:00</th>\n",
       "      <td>1.833988</td>\n",
       "      <td>18.834639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-05-21 22:06:00+00:00</th>\n",
       "      <td>1.567610</td>\n",
       "      <td>18.458077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-05-21 22:07:30+00:00</th>\n",
       "      <td>1.207911</td>\n",
       "      <td>18.109961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-05-21 22:09:00+00:00</th>\n",
       "      <td>1.435166</td>\n",
       "      <td>17.014766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-05-21 22:10:30+00:00</th>\n",
       "      <td>1.869589</td>\n",
       "      <td>16.976774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-05-21 22:12:00+00:00</th>\n",
       "      <td>1.855380</td>\n",
       "      <td>16.861258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-05-21 22:13:30+00:00</th>\n",
       "      <td>1.995521</td>\n",
       "      <td>16.243335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           pressure  temperature\n",
       "time                                            \n",
       "2014-05-21 22:00:00+00:00  1.751477    17.514350\n",
       "2014-05-21 22:01:30+00:00  1.477457    17.898020\n",
       "2014-05-21 22:03:00+00:00  1.741089    19.238910\n",
       "2014-05-21 22:04:30+00:00  1.833988    18.834639\n",
       "2014-05-21 22:06:00+00:00  1.567610    18.458077\n",
       "2014-05-21 22:07:30+00:00  1.207911    18.109961\n",
       "2014-05-21 22:09:00+00:00  1.435166    17.014766\n",
       "2014-05-21 22:10:30+00:00  1.869589    16.976774\n",
       "2014-05-21 22:12:00+00:00  1.855380    16.861258\n",
       "2014-05-21 22:13:30+00:00  1.995521    16.243335"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dst_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728be377-8e0b-4130-9d89-7ec09971ae25",
   "metadata": {},
   "source": [
    "#### Acoustic Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f919f6d6-d296-483b-8b64-62ba6ac79043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deployment_id</th>\n",
       "      <th>deploy_longitude</th>\n",
       "      <th>deploy_latitude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-05-22 09:40:30+00:00</th>\n",
       "      <td>10</td>\n",
       "      <td>-2.6812</td>\n",
       "      <td>46.1433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-05-22 09:46:08+00:00</th>\n",
       "      <td>42</td>\n",
       "      <td>5.7369</td>\n",
       "      <td>47.6660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           deployment_id  deploy_longitude  deploy_latitude\n",
       "time                                                                       \n",
       "2014-05-22 09:40:30+00:00             10           -2.6812          46.1433\n",
       "2014-05-22 09:46:08+00:00             42            5.7369          47.6660"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acoustic_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044dfc4f-9d98-4d85-8f24-8c4672a3f9d5",
   "metadata": {},
   "source": [
    "#### Tag Events DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be14ead8-6050-408f-a471-bb6b064de008",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_name</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-05-21 22:00:00+00:00</th>\n",
       "      <td>release</td>\n",
       "      <td>5.5369</td>\n",
       "      <td>47.966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06-02 06:00:00+00:00</th>\n",
       "      <td>fish_death</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           event_name  longitude  latitude\n",
       "time                                                      \n",
       "2014-05-21 22:00:00+00:00     release     5.5369    47.966\n",
       "2014-06-02 06:00:00+00:00  fish_death        NaN       NaN"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_tags_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce287ca-94ee-4bd2-a3dc-d5127ce91c9a",
   "metadata": {},
   "source": [
    "#### Tag Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e01ba360-cb19-4411-9cd7-12fa33aec037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pit_tag_number</th>\n",
       "      <th>acoustic_tag_id</th>\n",
       "      <th>scientific_name</th>\n",
       "      <th>common_name</th>\n",
       "      <th>project</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A123456</td>\n",
       "      <td>MAZ-42</td>\n",
       "      <td>Lorem ipsum</td>\n",
       "      <td>démo</td>\n",
       "      <td>how-to-guide</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pit_tag_number acoustic_tag_id scientific_name common_name       project\n",
       "0        A123456          MAZ-42     Lorem ipsum        démo  how-to-guide"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

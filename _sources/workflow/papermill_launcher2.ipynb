{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef2daa25-4ec9-4046-81cd-2644e2fb048b",
   "metadata": {},
   "source": [
    "# Tutorial: processing several tags with `kbatch_papermill`\n",
    "\n",
    "\n",
    "In this tutorial, we cover the handling of the processing of your biologging data, from hereafter referred to as _tags_.\n",
    "\n",
    "Here, we will illustrate the case where you want to run the fish tracking estimation model implemented by `pangeo-fish` _entirely_, for all your tags."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ceb6e7",
   "metadata": {},
   "source": [
    "As a biologist, you might wonder how to run the estimation model on all these data...\n",
    "\n",
    "This tutorial aims to clarify this point, by providing you _a way_ to automatically scale this processing!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24a06da",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The overall idea is the following:\n",
    "1. First, you write a Jupyter notebook that will perform all the operations you want for a tag (using some functions of `pangeo-fish`). It can be computing data, plotting some of the results along the way, checking the data as the cells go on etc.\n",
    "2. Then, thanks to a _launcher notebook_ we are going to learn to write here, you run _all the tags at once_, with whatever HPC resource you have access to.\n",
    "\n",
    "\n",
    "**Note that this workflow is compatible for any time of computation.**\n",
    "That being said, please be aware of the following limitations (and pitfalls):\n",
    "1. \"Inside\" the HPC, the notebooks will be run in containers, whose local storage is lost once the notebook is executed. As such, if the latter saves some data, make sure to send it somewhere (typically, to a S3 bucket).\n",
    "2. Since the run notebooks are retrieved after their execution, any interactive plot won't be shown. Therefore, we recommend considering either saving them (as HTML file for example) and adding cells in the notebook that would statically plot an equivalent plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199b7d38",
   "metadata": {},
   "source": [
    "### Technologies behind the _launcher notebook_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1c7077",
   "metadata": {},
   "source": [
    "The workflow covered in this tutorial, the _launcher notebook_, relies on `kbatch_papermill`, a package that lets you parametrize notebooks _and_ run them as jobs.\n",
    "\n",
    "Specifically `kbatch_papermill` is built on top of [`papermill`](https://papermill.readthedocs.io/en/latest/), a Python library that enable parameterized execution of Jupyter notebooks.\n",
    "`kbatch_papermill` provides a convenient API for running the aforementioned notebooks as jobs on your cluster.\n",
    "\n",
    "In fact, `kbatch_papermill` has been primarily designed for this use-case!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6f5221",
   "metadata": {},
   "source": [
    "\n",
    "To summarize, in this tutorial notebook, you will learn how to write a _launcher notebook_.\n",
    "Here, the routine we will set up is **the generation of fish location estimations** for your tags.\n",
    "<!-- First we define important parameters that will be used in the loop that executes the notebooks.\n",
    "The second part will generate ipynb files, based on a template noteboook, with the modified parameters, defined in the first cells of the notebook -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d40fc06",
   "metadata": {},
   "source": [
    "Before we set out to do anything, let's import all the required Python packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4bec0e-75c7-422d-8dd5-0d0d9c2c87ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import s3fs\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from kbatch_papermill import kbatch_papermill, print_job_status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f4f33a-4e6e-4871-af36-c5e1fedce33f",
   "metadata": {},
   "source": [
    "## Main inputs for _launcher notebook_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db23a97e",
   "metadata": {},
   "source": [
    "### a. Details\n",
    "In a nutshell, the notebook consists of submitting jobs to your HPC resources where the tasks are a parametrized notebook.\n",
    "\n",
    "The function used to submit the jobs is [`kbatch_papermill.kbatch_papermill`](https://kbatch-papermill.readthedocs.io/en/latest/api.html#kbatch_papermill.kbatch_papermill), which requires:\n",
    "1. Information about the notebook:\n",
    "    * `code_dir`: path to the folder containing the notebook. **The folder will be copied alongside the notebook itself**, allowing you to have access to any necessary file for your tasks.  \n",
    "    * `notebook`: the path to the notebook itself, relative to `code_dir`.\n",
    "2. Information about the remote storage of the notebook: \n",
    "    * `s3_dest`: the uri to save the notebook (once executed)\n",
    "\n",
    "_NB: `kbatch_papermill` does have more parameters, that you might be interested in using once you have gained more experience. In this tutorial, we will define them for you!_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2641d7a8",
   "metadata": {},
   "source": [
    "### b. Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a46927",
   "metadata": {},
   "source": [
    "First, clone the `pangeo-fish`'s repository to have the notebook:\n",
    "```bash\n",
    "# in a new terminal\n",
    "git clone https://github.com/pangeo-fish/pangeo-fish.git pangeo-fish\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183731a1-201f-4921-8f1a-b3c05243ee11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input/local variables\n",
    "code_dir = Path.home() / \"pangeo-fish\"\n",
    "notebook = \"notebooks/pangeo-fish.ipynb\"\n",
    "\n",
    "# where to store the result of this tutorial\n",
    "s3_dest = \"s3://gfts-ifremer/kbatch_papermill/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6009f3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional variables\n",
    "user_name = os.getenv(\"JUPYTERHUB_USER\")\n",
    "storage_options = {\n",
    "    \"anon\": False,\n",
    "    \"client_kwargs\": {\n",
    "        \"endpoint_url\": \"https://s3.gra.perf.cloud.ovh.net\",\n",
    "        \"region_name\": \"gra\",\n",
    "    },\n",
    "}\n",
    "# appends to `s3_dest` your username\n",
    "s3_dest += user_name\n",
    "s3_nb_dest = (\n",
    "    f\"{s3_dest}/nbs\"  # the notebooks will be stored in a dedicated directory \"nbs\"\n",
    ")\n",
    "# remote accessor\n",
    "s3 = s3fs.S3FileSystem(anon=False)\n",
    "s3.mkdir(s3_nb_dest, exist_ok=True)\n",
    "\n",
    "print(\"Remote storage root:\", s3_dest)\n",
    "print(\"Remote storage root for the notebooks:\", s3_nb_dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49d5150",
   "metadata": {},
   "source": [
    "Additionally, let's define a folder where we will save:\n",
    "1. Metadata of what we run (in a `.json` file `jobs.json`)\n",
    "2. Fetch the remotely stored notebooks (once they are executed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba560a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_output = Path(\"notebook_launcher_tutorial\")\n",
    "local_output.mkdir(exist_ok=True)\n",
    "job_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10714803",
   "metadata": {},
   "source": [
    "## Parametrizing and launching notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4f72e1",
   "metadata": {},
   "source": [
    "### a. Details\n",
    "\n",
    "In this tutorial, we simply run the example notebook included in the `pangeo-fish`'s repository, with different tag names.\n",
    "\n",
    "To do so, we need to change the variable `tag_name` of the notebook, since it corresponds to the name of the tag to process.\n",
    "For instance, let's run it for the tags `A19124`, `A18831` and `A18832`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6436d7c",
   "metadata": {},
   "source": [
    "### b. Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1795cc81-65d1-4118-8343-721e870b4dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"storage_options\": storage_options,\n",
    "    \"scratch_root\": s3_dest,  # in the notebook, the remote root is defined with the variable `scratch_root`\n",
    "    # URL to the reference data\n",
    "    \"ref_url\": \"s3://gfts-reference-data/NORTHWESTSHELF_ANALYSIS_FORECAST_PHY_004_013/combined_2022_to_2024.parq/\",\n",
    "}\n",
    "tag_list = [\"A19124\", \"A18831\", \"A18832\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d776aa6-569b-4240-83fd-38f6f169fa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag_name in tqdm(tag_list, desc=\"Processing tags\"):\n",
    "    try:\n",
    "        # remotes from the tag name any conflicting characters (such as \"_\") with Kubernetes\n",
    "        safe_tag_name = re.sub(r\"[^a-z0-9-]\", \"\", tag_name.lower())\n",
    "        # parameters (with `tag_name`)\n",
    "        params = parameters | {\"tag_name\": tag_name}\n",
    "        # where to store the notebook remotely\n",
    "        s3_nb_path = f\"{s3_nb_dest}/{tag_name}.ipynb\"\n",
    "\n",
    "        job_id = kbatch_papermill(\n",
    "            # input info\n",
    "            code_dir=code_dir,\n",
    "            notebook=notebook,\n",
    "            # output info\n",
    "            s3_dest=s3_nb_path,\n",
    "            parameters=params,\n",
    "            # additional parameters (not explained here)\n",
    "            job_name=f\"tuto-{safe_tag_name}\",  # name of the job (here, w.r.t the name of the tag)\n",
    "            s3_code_dir=f\"gfts-ifremer/kbatch/{user_name}\",  # where to zip and dump the code for the container\n",
    "            profile_name=\"big60\",  # specification of the container's hardware\n",
    "        )\n",
    "        print(\n",
    "            f'Notebook for the tag \"{tag_name}\" has been launched as the job \"{job_id}\"!'\n",
    "        )\n",
    "\n",
    "        # we keep the remote paths of the launched jobs\n",
    "        job_dict[job_id] = s3_nb_path\n",
    "    except Exception as e:\n",
    "        print(f\"Error for {tag_name}: {e.__class__.__name__}: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8a74a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saves the jobs' metadata in the local folder\n",
    "dict_path = local_output / \"jobs.json\"\n",
    "with dict_path.open(\"w\") as file:\n",
    "    json.dump(job_dict, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b75df4e",
   "metadata": {},
   "source": [
    "_You can monitor the status of the jobs with the following cell:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61bddd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_job_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db38abe",
   "metadata": {},
   "source": [
    "When the jobs are finished, you can fetch the notebooks locally with the remote accessor `s3`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a84d412-faee-44ea-8d34-1c8f6cb5638d",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.get(f\"{s3_nb_dest}/*\", local_output, recursive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff77727-7471-410f-a9f6-63c8780a8958",
   "metadata": {},
   "source": [
    "As for the the results of each notebook (or tag), they are stored next `s3_nb_dest`, under `s3_dest`.\n",
    "You can explore them with the `ls` function of `s3`:\n",
    "```Python\n",
    "s3.ls(s3_dest)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a457cae",
   "metadata": {},
   "source": [
    "### Further Readings\n",
    "\n",
    "* More information about the results, please check `pangeo-fish`'s [tutorial](https://pangeo-fish.readthedocs.io/en/latest/notebook.html).\n",
    "* To learn how to parameterize Jupyter notebooks, see [papermill documentation](https://papermill.readthedocs.io/en/latest/usage-workflow.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c74f6db",
   "metadata": {},
   "source": [
    "### Extended Code Explanation\n",
    "\n",
    "This section aims to provide you with additional explanations of the code.\n",
    "\n",
    "It targets users who want to gain better knowledge about the `kbatch_papermill` function.\n",
    "\n",
    "<!-- As such, in the following we assume you have already used on your own the package and are familiar with Python. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131ee1ac",
   "metadata": {},
   "source": [
    "The last parameters of `kbatch_papermill()` that are not covered above are the following:\n",
    "* `s3_code_dir`\n",
    "* `profile_name`\n",
    "\n",
    "There is little to add for `s3_code_dir`. \n",
    "It defines the path to a repository in which the files under `code_dir` are zipped into `.zip` files that is later sent to the kubernetes containers.\n",
    "Upon the execution of the containers, the `.zip` files are removed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee255e7f",
   "metadata": {},
   "source": [
    "As for `profile_name`, it defines the specification of the container's hardware resources.\n",
    "To see the available profiles of your HPC, open a terminal and run the following command:\n",
    "```bash\n",
    "kbatch profiles\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Launching the scientific plotting notebooks as jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's launch the previous notebook, that computes an example of scientific plot for result inspection and analysis, on the three tags that were run in the previous [`kbatch-papermill` tutorial](papermill_launcher2.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import s3fs\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from kbatch_papermill import kbatch_papermill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, clone the GFTS's repository to have the notebook we want to run:\n",
    "```bash\n",
    "# in a new terminal\n",
    "git clone https://github.com/destination-earth/DestinE_ESA_GFTS gfts\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input variables\n",
    "code_dir = Path.home() / \"gfts/docs\"\n",
    "notebook = \"workflow/compute.ipynb\"\n",
    "s3_dest = \"s3://gfts-ifremer/kbatch_papermill/\"  # we expect the results to be there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_name = os.getenv(\"JUPYTERHUB_USER\")\n",
    "storage_options = {\n",
    "    \"anon\": False,\n",
    "    \"client_kwargs\": {\n",
    "        \"endpoint_url\": \"https://s3.gra.perf.cloud.ovh.net\",\n",
    "        \"region_name\": \"gra\",\n",
    "    },\n",
    "}\n",
    "s3_dest += user_name\n",
    "# the notebooks will be stored there (feel free to change it)\n",
    "s3_nb_dest = f\"{s3_dest}/nbs\"\n",
    "print(\"Remote storage root:\", s3_dest)\n",
    "print(\"The notebooks will be saved in:\", s3_nb_dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input parameters for the notebook\n",
    "parameters = {\n",
    "    # remote accessor configuration\n",
    "    \"storage_options\": storage_options,\n",
    "    # path to where the biologging data has been formatted\n",
    "    \"tag_root\": \"https://data-taos.ifremer.fr/data_tmp/cleaned/tag/\",\n",
    "    # path the results\n",
    "    \"result_root\": s3_dest,\n",
    "}\n",
    "tag_list = [\"A19124\", \"A18831\", \"A18832\"]\n",
    "job_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag_name in tqdm(tag_list, desc=\"Processing tags\"):\n",
    "    try:\n",
    "        safe_tag_name = re.sub(r\"[^a-z0-9-]\", \"\", tag_name.lower())\n",
    "        # parameters (with `tag_name`)\n",
    "        params = parameters | {\"tag_name\": tag_name}\n",
    "        s3_nb_path = f\"{s3_nb_dest}/{tag_name}2.ipynb\"\n",
    "\n",
    "        print(code_dir, notebook, s3_nb_path)\n",
    "\n",
    "        job_id = kbatch_papermill(\n",
    "            # input info\n",
    "            code_dir=code_dir,\n",
    "            notebook=notebook,\n",
    "            # output info\n",
    "            s3_dest=s3_nb_path,\n",
    "            parameters=params,\n",
    "            # additional parameters (not explained here)\n",
    "            job_name=f\"html-{safe_tag_name}\",  # name of the job (here, w.r.t the name of the tag)\n",
    "            s3_code_dir=f\"gfts-ifremer/kbatch/{user_name}\",  # where to zip and dump the code for the container\n",
    "            profile_name=\"default\",  # specification of the container's hardware\n",
    "        )\n",
    "        print(\n",
    "            f'Notebook for the tag \"{tag_name}\" has been launched as the job \"{job_id}\"!'\n",
    "        )\n",
    "\n",
    "        # we keep the remote paths of the launched jobs\n",
    "        job_dict[job_id] = s3_nb_path\n",
    "    except Exception as e:\n",
    "        print(f\"Error for {tag_name}: {e.__class__.__name__}: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the jobs are finished _(and assuming they succeeded)_, a plot for the scientific validation has been saved as a HTML file `ts_track_plot.html` in each tag folder under `result_root`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3fs.S3FileSystem(**storage_options).ls(f\"{s3_dest}/{tag_list[0]}/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
